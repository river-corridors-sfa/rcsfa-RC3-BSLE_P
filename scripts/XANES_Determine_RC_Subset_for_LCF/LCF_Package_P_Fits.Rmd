---
title: "LCF_Package_P_Fits"
author: "Morgan Barnes"
date: "'2023-08-18'r Sys.Date()'"
output: html_document
---


####Overview

#All sample and standard spectra scans were averaged in Sam's pack, imported to Athena for energy shift, and exported as .xmu data file (non-normalized spectra). Normalization parameters in .xmu files are only estimates and do not necessarily represent the best background subtraction and normalization parameters
#Make sure to have a csv with background subtraction and normalization details for the Athena fit function. This file is named File_BS_Norm_Parameters.csv
#Reminder that R can't overwrite files with the same name so make sure all sample and reference compounds have unique names
#For samples with -0.7filt, the period between 0 and 7 was removed in the imported files and File_BS_Norm_Parameters file 
#This script was run locally, so will be need to be modified for future use
# .xmu files for samples and reference compounds can be downloaded from Grieger et al. (2023): BSLE v3 data package URL: https://data.ess-dive.lbl.gov/view/doi:10.15485/1894135
# Background subtractions and normalization parameters can be found in the manuscript-level data package (Barnes et al., in prep)


#LCF package details: https://cran.r-project.org/web/packages/LCF/LCF.pdf

#contact: Morgan Barnes morgan.barnes@pnnl.gov



## Set Up
```{r setup, include=FALSE, dev="CairoPNG"}
rm(list=ls(all=T))
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries
```{r library}

require(pacman)

pacman::p_load(LCF, scales, dplyr)
```

### Confirm working directory:
```{r working directory check, echo=FALSE}
getwd()
```

## Read raw spectra, normalize, LCF
```{r read spectra, include=T, results=F, message=F, warning=F}
#Find files that are samples and standards
samples = list.files(pattern = "BSLE")
stds = list.files(pattern = "std")

#Read in different background correction and normalization values for standards and samples
val = read.csv("File_BS_Norm_Parameters.csv")
std.val = val[grep("std",val$File_Name),]
samples.val = val[grep("BSLE",val$File_Name),]


## Background correction and normalization
#This function allows you to base-line correct and edge-step normalize XANES spectra (background correction). Raw spectra are loaded, then base-line corrected and edge-step normalized. The spectrum is flattened after E0. The function returns the corrected, normalized and flattened spectrum.
std.spectra = list() # create an empty list
corr.spec.standards = list() 
corr.norm.standards = list() 

#Read in the stds and correct them with different background values
for (i in 1:length(stds)){
  temp = read_raw_spec(stds[i],
                        use.eshift = F)
  std.spectra = append(std.spectra,temp) # append samples to the list
  
#Select the correct set of background values for each std spectra
  temp.val = subset(std.val,std.val$File_Name == stds[i])
  temp.standards  = initial_load(temp,   corr.norm = c(temp.val$Pre_Edge_Range_Start, temp.val$Pre_Edge_Range_End, temp.val$Normalization_Range_Start, temp.val$Normalization_Range_End))
  
  corr.spec.standards = append(corr.spec.standards,temp.standards)
  
  temp.corr.standards = bkg_corr(temp.standards[[1]],   corr.norm = c(temp.val$Pre_Edge_Range_Start, temp.val$Pre_Edge_Range_End, temp.val$Normalization_Range_Start, temp.val$Normalization_Range_End))
  
    corr.norm.standards = append(corr.norm.standards,temp.corr.standards)
    
#Plots
  pdf(paste0(getwd(),"/plots/","Baseline_Correction_",stds[i],".pdf")) 
  plot(temp.corr.standards$energy, temp.corr.standards$cor.absorption, type = "l",
       main = stds[i],
       xlab = "Energy (eV)",
       ylab = "Normalized Absorption (arb. units)")
dev.off()
 
}

#Read the samples and background correct
spectra = list() # create an empty list
corr.spec.samples = list() 
corr.norm.samples = list()

for (i in 1:length(samples)){
  temp = read_raw_spec(samples[i],
                        use.eshift = F)
  spectra = append(spectra,temp) # append samples to the list
  
#Select the correct set of background values for each std spectra
  temp.val = subset(samples.val,samples.val$File_Name == samples[i])
  temp.samples  = initial_load(temp,   corr.norm = c(temp.val$Pre_Edge_Range_Start, temp.val$Pre_Edge_Range_End, temp.val$Normalization_Range_Start, temp.val$Normalization_Range_End))
  
  corr.spec.samples = append(corr.spec.samples,temp.samples)
  
  temp.corr.samples = bkg_corr(temp.samples[[1]],   corr.norm = c(temp.val$Pre_Edge_Range_Start, temp.val$Pre_Edge_Range_End, temp.val$Normalization_Range_Start, temp.val$Normalization_Range_End))
  
     corr.norm.samples = append(corr.norm.samples,temp.corr.samples)
     
#Plots
 pdf(paste0(getwd(),"/plots/","Baseline_Correction_",samples[i],".pdf"))     
  plot(temp.corr.samples$energy, temp.corr.samples$cor.absorption, type = "l",
       main = samples[i],
       xlab = "Energy (eV)",
       ylab = "Normalized Absorption (arb. units)")
dev.off()
}


##Linear combination fit: determine probable reference compounds in samples to narrow down the number used in the Athena Program fits

# Standards 
## exclude portions smaller 5% = 0.05
athena.fit.exclude <- fit_athena(all.samples = corr.spec.samples,
all.standards = corr.spec.standards,
LC.vals = c(-10, 30), amoSTD = 3, ex.smaller = 0.05, file.output = TRUE, best.fits = 20)

#convert to percent
athena.fit.exclude <- athena.fit.exclude %>% mutate_if(is.character, as.numeric)
fit2 = athena.fit.exclude %>% dplyr::select(R.fac)
fit.temp = athena.fit.exclude %>% dplyr::select(-R.fac)
for (i in 1:ncol(fit.temp)){
  fit.temp[,i] = round(fit.temp[,i] * 100,1)
}

fit.temp$Sum = rowSums(fit.temp)
athena.final = cbind(fit.temp,fit2)

write.csv(athena.final,paste0(getwd(),"/Athena_Code_Output/Fit_using_athena_fit_excluding_portions_results.csv"),row.names = T)

#make figures of Athena LCF
athena.fit.exclude$pre.adj.1 = NA
athena.fit.exclude$pre.adj.2 = NA
athena.fit.exclude$post.adj.1 = NA
athena.fit.exclude$post.adj.2 = NA

sample.name = paste0(rownames(athena.fit.exclude[1,]),".xmu")
sample.name2 = gsub(".xmu","",sample.name)
athena.fit.exclude$pre.adj.1[1:20] = samples.val$Pre_Edge_Range_Start[which(samples.val$File_Name==sample.name)]
athena.fit.exclude$pre.adj.2[1:20] = samples.val$Pre_Edge_Range_End[which(samples.val$File_Name==sample.name)]
athena.fit.exclude$post.adj.1[1:20] = samples.val$Normalization_Range_Start[which(samples.val$File_Name==sample.name)]
athena.fit.exclude$post.adj.2[1:20] = samples.val$Normalization_Range_End[which(samples.val$File_Name==sample.name)]

pdf(paste0(getwd(),"/Athena_Code_Output/plots/Athena_LCF_",sample.name2,".pdf"))
par(pty="s")
plot_LCF(all.samples = corr.spec.samples[1],
all.standards = corr.spec.standards, LCF.res = athena.fit.exclude[1,], LC.vals = c(-10,30),corr.norm = c(-13.4, -6, 30, 55.6))
dev.off()

# Running the rest of the samples
for(i in 2:length(samples)){
  
sample.name = samples[i]
sample.name2 = gsub(".xmu","",sample.name)
athena.fit.exclude$pre.adj.1[grep(sample.name2,rownames(athena.fit.exclude)):(grep(sample.name2,rownames(athena.fit.exclude))+19)] = samples.val$Pre_Edge_Range_Start[which(samples.val$File_Name==sample.name)]
athena.fit.exclude$pre.adj.2[grep(sample.name2,rownames(athena.fit.exclude)):(grep(sample.name2,rownames(athena.fit.exclude))+19)]= samples.val$Pre_Edge_Range_End[which(samples.val$File_Name==sample.name)]
athena.fit.exclude$post.adj.1[grep(sample.name2,rownames(athena.fit.exclude)):(grep(sample.name2,rownames(athena.fit.exclude))+19)] = samples.val$Normalization_Range_Start[which(samples.val$File_Name==sample.name)]
athena.fit.exclude$post.adj.2[grep(sample.name2,rownames(athena.fit.exclude)):(grep(sample.name2,rownames(athena.fit.exclude))+19)] = samples.val$Normalization_Range_End[which(samples.val$File_Name==sample.name)]

pdf(paste0(getwd(),"/Athena_Code_Output/plots/Athena_LCF_",sample.name2,".pdf"))
par(pty="s")
  plot_LCF(all.samples = corr.spec.samples[i],
all.standards = corr.spec.standards, LCF.res = athena.fit.exclude[grep(sample.name2,rownames(athena.fit.exclude)),], LC.vals = c(-10,30),corr.norm = c(-13.4, -6, 30, 55.6))
  dev.off()
  
}
```

